{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "388e6316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c413b77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: 0.06\n",
      "State: 0 v probs: [0.219 0.278 0.234 0.269]\n",
      "State: 1 v probs: [0.251 0.292 0.262 0.195]\n",
      "State: 2 > probs: [0.247 0.236 0.307 0.209]\n",
      "State: 3 v probs: [0.242 0.261 0.241 0.256]\n",
      "State: 4 ^ probs: [0.255 0.258 0.228 0.259]\n",
      "State: 5 < probs: [0.25 0.25 0.25 0.25]\n",
      "State: 6 v probs: [0.263 0.302 0.231 0.203]\n",
      "State: 7 < probs: [0.25 0.25 0.25 0.25]\n",
      "State: 8 v probs: [0.205 0.294 0.267 0.235]\n",
      "State: 9 > probs: [0.228 0.265 0.282 0.225]\n",
      "State: 10 v probs: [0.275 0.293 0.29  0.142]\n",
      "State: 11 < probs: [0.25 0.25 0.25 0.25]\n",
      "State: 12 < probs: [0.25 0.25 0.25 0.25]\n",
      "State: 13 > probs: [0.196 0.241 0.283 0.279]\n",
      "State: 14 > probs: [0.081 0.281 0.377 0.261]\n",
      "State: 15 < probs: [0.25 0.25 0.25 0.25]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"FrozenLake-v1\",is_slippery=True)\n",
    "policy = np.ones((16,4))/4\n",
    "\n",
    "for episode in range(10000):\n",
    "    state,_ = env.reset()\n",
    "    states,actions,rewards = [],[],[]\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = np.random.choice(4,p=policy[state])\n",
    "        next_state,reward,done,_,_ = env.step(action)\n",
    "        states.append(state)\n",
    "        rewards.append(reward)\n",
    "        actions.append(action)\n",
    "        state=next_state\n",
    "\n",
    "    G=0\n",
    "    returns=[]\n",
    "    for r in reversed(rewards):\n",
    "        G = r+0.99*G\n",
    "        returns.insert(0,G)\n",
    "\n",
    "    if returns:\n",
    "        baseline = np.mean(returns)\n",
    "        for s,a,Gt in zip(states,actions,returns):\n",
    "            policy[s,a] += 0.1 * (Gt-baseline)\n",
    "            policy[s] = np.maximum(policy[s],0.01)\n",
    "            policy[s] /= np.sum(policy[s])\n",
    "\n",
    "success=0\n",
    "for _ in range(100):\n",
    "    state,_ = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = np.argmax(policy[s])\n",
    "        state,reward,done,_,_ = env.step(action)\n",
    "        success += reward\n",
    "\n",
    "print(f\"Success: {success/100}\")\n",
    "arrows=['<','v','>','^']\n",
    "for s in range(16):\n",
    "    best_a = np.argmax(policy[s])\n",
    "    print(f\"State: {s} {arrows[best_a]} probs: {np.round(policy[s],3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6944a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
